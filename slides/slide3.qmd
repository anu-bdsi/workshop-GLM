---
title: General structure and diagnostics
subtitle: "{{< var workshop-title >}}"
format:
  anu-light-revealjs:
    #navigation-mode: vertical
    width: 1920
    height: 1080
    auto-stretch: false
    html-math-method: katex
    self-contained: true
    css: 
     - /assets/slides.css
    footer: "{{< var workshop-url >}}"
author: Emi Tanaka
institute: Biological Data Science Institute
date: 2024/09/27
date-format: "D[th] MMMM YYYY"
filters:
  - webr
execute: 
  echo: true
webr: 
  show-startup-message: false  
  packages: 
    - tidyverse
---



```{r, include = FALSE}
library(tidyverse)
library(patchwork)
source("setup.R")
theme_set(theme_classic(base_size = 24) + 
            theme(plot.title.position = "plot",
                  plot.background = element_rect(fill = "transparent", color = "transparent"),
                  legend.background = element_rect(fill = "transparent"),
                  panel.background = element_rect(fill = "transparent")))
```




## Probability Distributions 

![](/images/dist-binomial.png) ![](/images/dist-poisson.png) ![](/images/dist-neg-binomial.png) ![](/images/dist-geom.png) ![](/images/dist-betabinom.png) ![](/images/dist-hyper.png) ![](/images/dist-unif.png) ![](/images/dist-normal.png) ![](/images/dist-gamma.png)  ![](/images/dist-beta.png) ![](/images/dist-exp.png)  ![](/images/dist-cauchy.png)    ![](/images/dist-t.png)
![](/images/dist-f.png) ![](/images/dist-chi.png) ![](/images/dist-lnormal.png) ![](/images/dist-invg.png) ![](/images/dist-skewnormal.png) 

## Generalised linear models 

Generalised linear models (GLMs) has two components:

::: callout-note 

## A random component

$Y_i$ has a distribution from the exponential family with mean $\mu_i = E(Y_i)$.

:::

::: callout-note 

## A systematic component

A **linear predictor**: $$g(\mu_i) = \eta_i = o_i + \beta_0 + \beta_1 x_{i1} + \ldots + \beta_k x_{ik}$$ 

where 

- $g(\cdot)$ is a (smooth and invertible) **link function**, and
- $o_i$ is the offset value for the $i$-th observation (if any).

:::


## Exponential family 

<details>

::: {.callout-note appearance="minimal"}

A distribution is part of the exponential family if the probability density/mass function can be written in the form:

$$f(y;\theta, \phi) = a(y, \theta)\text{exp}\left(\frac{y\cdot\theta - \kappa(\theta)}{\phi}\right)$$

- $\theta$ is the _canonical parameter_
- $\kappa(\theta)$ is a known function called the _cumulant function_
- $\phi > 0$ is the _dispersion parameter_
- $a(y, \theta)$ is a _normalising constant_.

:::

</details>

![](/images/dist-binomial.png) ![](/images/dist-poisson.png) ![](/images/dist-neg-binomial.png) ![](/images/dist-geom.png) ![](/images/dist-betabinom.png){style="opacity:0.3;"} ![](/images/dist-hyper.png){style="opacity:0.3;"} ![](/images/dist-unif.png){style="opacity:0.3;"} ![](/images/dist-normal.png) ![](/images/dist-gamma.png)  ![](/images/dist-beta.png) ![](/images/dist-exp.png)  ![](/images/dist-cauchy.png){style="opacity:0.3;"}    ![](/images/dist-t.png){style="opacity:0.3;"}
![](/images/dist-f.png){style="opacity:0.3;"} ![](/images/dist-chi.png) ![](/images/dist-lnormal.png) ![](/images/dist-invg.png) ![](/images/dist-skewnormal.png){style="opacity:0.3;"} 







## Common GLMs


| Family | Default Link | $g(\mu)$ | $g^{-1}(\eta)$ | Range of $Y_i$ | $Var(\mu)$ |
|--------|--------|---------|---------------|-------| --- |
| Normal/Gaussian | Identity | $\mu$ | $\eta$ | $(-\infty, \infty)$ | $1$ |
| Gamma | Inverse | $\frac{1}{\mu}$ | $\frac{1}{\eta}$ | $(0, \infty)$ | $\mu^2$ |
| Binomial | Logit | $\log_e(\frac{\mu}{1 - \mu})$ |  $\frac{\text{exp}(\eta)}{1 + \text{exp}(\eta)}$ | $[0, 1]$ | $\mu(1-\mu)$ |
| Poisson | Log | $\log_e(\mu)$ | $\text{exp}(\eta)$|$[0, \infty)$ | $\mu$ |
| Negative Binomial | Log |$\log_e(\mu)$ | $\text{exp}(\eta)$| $[0, \infty)$ | $\mu + \mu^2/k$ |




- $\mu$ is the expected value on the response scale
- $\eta$ is the expected value on the link scale

## {{< fa brands r-project >}}  Fitting GLMs in R

`glm(y ~ x, family = dist(link = "function"), data = data)`

<br>

| Family | Function | Default Link | Other Links |
|-----|---|------|-----|
| Normal/Gaussian | `gaussian` | identity | log, inverse |
| Gamma | `Gamma` | inverse | identity, log|
| Binomial | `binomial` | logit | probit, cauchit, log, cloglog |
| Poisson | `poisson` | log | log, identity, sqrt |
| Negative Binomial<sup>*</sup> | `MASS::glm.nb` | log | sqrt, identity |

- The default links in R are the **canonical link** (except for the Negative Binomial)
- <sup>*</sup>Negative Binomial is specified with `glm.nb` from the `MASS` package and does not require family to be specified.


## Which GLM to use?

::: incremental

- For the _random component_: 
    - What is the response type? E.g. positive integer, continuous over infinite support, etc.
    - Look at the relationship between the group mean and the group variance<br>(left as an exercises -- see Exercise 3)
- For the _systematic component_: 
    - How are the explanatory variables related to the mean of the response variable?
    - Do the explanatory variables need to be transformed or removed?
- For the _practical component_:
  - Are the interpretation from the fitted model understandable?
  - Can you fit the model in practice?
    
:::



```{r}
#| include: false
#| fig-width: 18
#| fig-height: 12
gnormal <- tibble(y = seq(-4, 4, length.out = 1000)) |> 
  mutate(p = dnorm(y, 0, 1)) |> 
  ggplot() + geom_col(aes(y, p)) +
  labs(title = "Y ~ N(0, 1)", x = "Y", y = "Density") +
  scale_y_continuous(expand = c(0, 0))

gnormal2 <- gnormal %+% (
  tibble(y = seq(-4, 4, length.out = 1000)) |> 
    mutate(p = dnorm(y, 1, 1))) +
  labs(title = "Y ~ N(1, 1)")

gnormal3 <- gnormal %+% (
  tibble(y = seq(-4, 4, length.out = 1000)) |> 
    mutate(p = dnorm(y, 0, 0.5))) +
  labs(title = "Y ~ N(0, 0.5)")

ggamma <- gnormal %+% (
  tibble(y = seq(0, 15, length.out = 1000)) |> 
    mutate(p = dgamma(y, 1))) +
  labs(title = "Y ~ Gamma(1, 1)")

ggamma2 <- gnormal %+% (
  tibble(y = seq(0, 15, length.out = 1000)) |> 
    mutate(p = dgamma(y, 5))) +
  labs(title = "Y ~ Gamma(5, 1)")

ggamma3 <- gnormal %+% (
  tibble(y = seq(0, 80, length.out = 1000)) |> 
    mutate(p = dgamma(y, 10, 1/3))) +
  labs(title = "Y ~ Gamma(10, 1/3)")

ginvnorm <- gnormal %+% (
  tibble(y = seq(0, 5, length.out = 1000)) |> 
    mutate(p = statmod::dinvgauss(y, 1))) +
  labs(title = "Y ~ Inverse Gaussian(1, 1)")

ginvnorm2 <- gnormal %+% (
  tibble(y = seq(0, 5, length.out = 1000)) |> 
    mutate(p = statmod::dinvgauss(y, 5))) +
  labs(title = "Y ~ Inverse Gaussian(5, 1)")

ginvnorm3 <- gnormal %+% (
  tibble(y = seq(0, 5, length.out = 1000)) |> 
    mutate(p = statmod::dinvgauss(y, 1, dispersion = 1/3))) +
  labs(title = "Y ~ Inverse Gaussian(1, 1/3)")




(gnormal  + ggamma + ginvnorm ) / (gnormal2  + ggamma2 + ginvnorm2 )  / (gnormal3  + ggamma3 + ginvnorm3 ) 
```


```{r}
#| include: false
#| fig-width: 18
#| fig-height: 12
gbernoulli <- tibble(y = 0:10) |> 
  mutate(p = dbinom(y, 1, 0.3)) |> 
  ggplot() + geom_col(aes(y, p)) +
  labs(title = "Y ~ Bernoulli(0.3)", x = "Y", y = "Probability") +
  scale_y_continuous(expand = c(0, 0)) + 
  scale_x_continuous(breaks = 0:10)

gbinom <- gbernoulli %+% (tibble(y = 0:10) |> 
  mutate(p = dbinom(y, 10, 0.7))) +
  labs(title = "Y ~ Binomial(10, 0.7)")

gbinom2 <- gbernoulli %+% (tibble(y = 0:10) |> 
  mutate(p = dbinom(y, 10, 0.3))) +
  labs(title = "Y ~ Binomial(10, 0.3)")



gnbinom <- gbernoulli %+% (
  tibble(y = 0:30) |> 
    mutate(p = dnbinom(y, 5, 0.5))) +
  labs(title = "Y ~ Negative Binomial(5, 0.5)") +
  scale_x_continuous()

gnbinom2 <- gbernoulli %+% (
  tibble(y = 0:30) |> 
    mutate(p = dnbinom(y, 10, 0.7)) ) +
  labs(title = "Y ~ Negative Binomial(10, 0.7)") +
  scale_x_continuous()

gnbinom3 <- gbernoulli %+% (
  tibble(y = 0:60) |> 
    mutate(p = dnbinom(y, 10, 0.3))) +
  labs(title = "Y ~ Negative Binomial(10, 0.3)") +
  scale_x_continuous()

gpois <- gbernoulli %+% (tibble(y = 0:15) |> 
  mutate(p = dpois(y, 5)) |> 
  filter(p > 0)) +
  labs(title = "Y ~ Poisson(5)") +
  scale_x_continuous()

gpois2 <- gbernoulli %+% (tibble(y = 0:15) |> 
  mutate(p = dpois(y, 1)) |> 
  filter(p > 0)) +
  labs(title = "Y ~ Poisson(1)") +
  scale_x_continuous()

gpois3 <- gbernoulli %+% (tibble(y = 0:15) |> 
  mutate(p = dpois(y, 0.5)) |> 
  filter(p > 0)) +
  labs(title = "Y ~ Poisson(0.5)") +
  scale_x_continuous()


(gbernoulli + gnbinom + gpois) / (gbinom + gnbinom2 + gpois2) / (gbinom2 + gnbinom3 + gpois3)
```

# Diagnostics {background-color="#F5EDDE"}


## Residual plot

- Plots of residuals vs fitted values and each of the covariates is important to check.
- If there are any trends in the plot, then the systematic component can be improved, e.g. change the link function, add extra predictors or transform predictors. 
- If the random component is correct, then the variance should be approximately constant across fitted values and predictors. 
- For discrete responses, it is better to use quantile residuals. 

## Quantile residual plot



```{r}
#| code-fold: true
cancer <- read_csv("https://anu-bdsi.github.io/workshop-GLM/data/cancer.csv")
cancer_fit <- glm(diagnosis_malignant ~ radius_mean + concave_points_mean, 
                  data = cancer, 
                  family = binomial(link = "logit"))

cancer_augment <- cancer_fit |> 
  broom::augment(type.predict = "response") |> 
  mutate(qres = statmod::qresid(cancer_fit))
```

::: columns

::: {.column width="50%"}


```{r}
#| code-fold: true
cancer_augment |> 
  ggplot(aes(.fitted, .resid)) +
    geom_point() + 
    geom_hline(yintercept = 0, linetype = 2) +
    labs(y = "Deviance residuals", x = "Fitted values")
```

:::

::: {.column width="50%"}


```{r}
#| code-fold: true
cancer_augment |> 
  ggplot(aes(.fitted, qres)) +
    geom_point() + 
    geom_hline(yintercept = 0, linetype = 2) +
    labs(y = "Quantile residuals", x = "Fitted values")
```


:::

:::

## Q-Q plot 

::: columns

::: {.column width="30%"}

```{r}
#| code-fold: true
#| fig-width: 6
#| fig-height: 6
cancer_augment |> 
  ggplot(aes(sample = qres)) +
    stat_qq() + 
    stat_qq_line() +
    labs(title = "Q-Q plot of quantile residuals",
         x = "Theoretical quantiles", 
         y = "Sample quantiles")
```

:::

::: {.column width="70%" .fragment}


Simulate from fitted model and check the Q-Q plot of quantile residuals to know the "typical" Q-Q plot:

```{r}
#| code-fold: true
#| fig-width: 18
#| fig-height: 12
simulate(cancer_fit, nsim = 6) |> 
  bind_cols(cancer) |> 
  pivot_longer(starts_with("sim_"),
               names_to = "sim",
               values_to = "sim_response") |> 
  nest(.by = sim) |> 
  mutate(fit = map(data, ~update(cancer_fit, data = .))) |> 
  mutate(qres = map(fit, ~statmod::qresid(.))) |> 
  unnest_longer(qres) |> 
  ggplot(aes(sample = qres)) +
  stat_qq() +
  stat_qq_line() + 
  facet_wrap(~sim) + 
  coord_equal()
```


:::

:::




## Summary 

- A generalised linear model are regression models that consist of two components:
  - a random component (requiring decision on a distribution from the exponential family): $$Y_i \sim \text{Exponential family}$$
  - a systematic component (requiring decision on the link function): $$g(\mu_i) = \eta_i = o_i + \beta_0 + \beta_1 x_{i1} + \ldots + \beta_k x_{ik}.$$
- Diagnose the model using (quantile) residual plots and Q-Q plots.
