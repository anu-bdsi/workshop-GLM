---
title: Generalised linear models
subtitle: "{{< var workshop-title >}}"
format:
  anu-light-revealjs:
    width: 1920
    height: 1080
    auto-stretch: false
    html-math-method: katex
    self-contained: true
    css: 
     - /assets/slides.css
    footer: "{{< var workshop-url >}}"
author: Emi Tanaka
institute: Biological Data Science Institute
date: 2024/09/27
date-format: "D[th] MMMM YYYY"
filters:
  - webr
execute: 
  echo: true
webr: 
  show-startup-message: false  
  packages: 
    - tidyverse
    - agridat
    - palmerpenguins
    - maps
---


## {{< fa crosshairs >}} Current learning objective

```{r, include = FALSE}
library(tidyverse)
library(patchwork)
source("setup.R")
theme_set(theme_classic(base_size = 24) + 
            theme(plot.title.position = "plot",
                  plot.background = element_rect(fill = "transparent", color = "transparent"),
                  legend.background = element_rect(fill = "transparent"),
                  panel.background = element_rect(fill = "transparent")))
```


```{r}
#| results: asis 
#| echo: false
learning_objectives(3)
```


## Continuous Distributions 



```{r}
#| echo: false
#| fig-width: 18
#| fig-height: 12
gnormal <- tibble(y = seq(-4, 4, length.out = 1000)) |> 
  mutate(p = dnorm(y, 0, 1)) |> 
  ggplot() + geom_col(aes(y, p)) +
  labs(title = "Y ~ N(0, 1)", x = "Y", y = "Density") +
  scale_y_continuous(expand = c(0, 0))

gnormal2 <- gnormal %+% (
  tibble(y = seq(-4, 4, length.out = 1000)) |> 
    mutate(p = dnorm(y, 1, 1))) +
  labs(title = "Y ~ N(1, 1)")

gnormal3 <- gnormal %+% (
  tibble(y = seq(-4, 4, length.out = 1000)) |> 
    mutate(p = dnorm(y, 0, 0.5))) +
  labs(title = "Y ~ N(0, 0.5)")

ggamma <- gnormal %+% (
  tibble(y = seq(0, 15, length.out = 1000)) |> 
    mutate(p = dgamma(y, 1))) +
  labs(title = "Y ~ Gamma(1, 1)")

ggamma2 <- gnormal %+% (
  tibble(y = seq(0, 15, length.out = 1000)) |> 
    mutate(p = dgamma(y, 5))) +
  labs(title = "Y ~ Gamma(5, 1)")

ggamma3 <- gnormal %+% (
  tibble(y = seq(0, 15, length.out = 1000)) |> 
    mutate(p = dgamma(y, 1, 1/3))) +
  labs(title = "Y ~ Gamma(1, 1/3)")

ginvnorm <- gnormal %+% (
  tibble(y = seq(0, 5, length.out = 1000)) |> 
    mutate(p = statmod::dinvgauss(y, 1))) +
  labs(title = "Y ~ Inverse Gaussian(1, 1)")

ginvnorm2 <- gnormal %+% (
  tibble(y = seq(0, 5, length.out = 1000)) |> 
    mutate(p = statmod::dinvgauss(y, 5))) +
  labs(title = "Y ~ Inverse Gaussian(5, 1)")

ginvnorm3 <- gnormal %+% (
  tibble(y = seq(0, 5, length.out = 1000)) |> 
    mutate(p = statmod::dinvgauss(y, 1, dispersion = 1/3))) +
  labs(title = "Y ~ Inverse Gaussian(1, 1/3)")




(gnormal  + ggamma + ginvnorm ) / (gnormal2  + ggamma2 + ginvnorm2 )  / (gnormal3  + ggamma3 + ginvnorm3 ) 
```


## Discrete Distributions 


```{r}
#| echo: false
#| fig-width: 18
#| fig-height: 12
gbernoulli <- tibble(y = 0:10) |> 
  mutate(p = dbinom(y, 1, 0.3)) |> 
  ggplot() + geom_col(aes(y, p)) +
  labs(title = "Y ~ Bernoulli(0.3)", x = "Y", y = "Probability") +
  scale_y_continuous(expand = c(0, 0)) + 
  scale_x_continuous(breaks = 0:10)

gbinom <- gbernoulli %+% (tibble(y = 0:10) |> 
  mutate(p = dbinom(y, 10, 0.7))) +
  labs(title = "Y ~ Binomial(10, 0.7)")

gbinom2 <- gbernoulli %+% (tibble(y = 0:10) |> 
  mutate(p = dbinom(y, 10, 0.3))) +
  labs(title = "Y ~ Binomial(10, 0.3)")



gnbinom <- gbernoulli %+% (
  tibble(y = 0:30) |> 
    mutate(p = dnbinom(y, 5, 0.5))) +
  labs(title = "Y ~ Negative Binomial(5, 0.5)") +
  scale_x_continuous()

gnbinom2 <- gbernoulli %+% (
  tibble(y = 0:30) |> 
    mutate(p = dnbinom(y, 10, 0.7)) ) +
  labs(title = "Y ~ Negative Binomial(10, 0.7)") +
  scale_x_continuous()

gnbinom3 <- gbernoulli %+% (
  tibble(y = 0:60) |> 
    mutate(p = dnbinom(y, 10, 0.3))) +
  labs(title = "Y ~ Negative Binomial(10, 0.3)") +
  scale_x_continuous()

gpois <- gbernoulli %+% (tibble(y = 0:15) |> 
  mutate(p = dpois(y, 5)) |> 
  filter(p > 0)) +
  labs(title = "Y ~ Poisson(5)") +
  scale_x_continuous()

gpois2 <- gbernoulli %+% (tibble(y = 0:15) |> 
  mutate(p = dpois(y, 1)) |> 
  filter(p > 0)) +
  labs(title = "Y ~ Poisson(1)") +
  scale_x_continuous()

gpois3 <- gbernoulli %+% (tibble(y = 0:15) |> 
  mutate(p = dpois(y, 0.5)) |> 
  filter(p > 0)) +
  labs(title = "Y ~ Poisson(0.5)") +
  scale_x_continuous()


(gbernoulli + gnbinom + gpois) / (gbinom + gnbinom2 + gpois2) / (gbinom2 + gnbinom3 + gpois3)
```

## Generalised linear models 

Genralised linear models (GLMs) has three components:

- Assume that $Y_i$ is a member of an exponential family (e.g. Normal/Gaussian, Binomial, Poission, Gamma, etc).
- A linear predictor $\eta_i = \beta_0 + \beta_1 x_{i1} + \ldots + \beta_k x_{ik}.$
- A (smooth and invertible) link function $g(\cdot)$ which transforms the expectation of the response variable $\mu_i = E(Y_i)$ to the linear predictor: $$g(\mu_i) = \eta_i = \beta_0 + \beta_1 x_{i1} + \ldots + \beta_k x_{ik}.$$

## Link functions 

| Link | $\eta_i = g(\mu_i)$ | $\mu_i = g^{-1}(\eta_i)$ | 
|------|----------------------|--------------------------|
| Identity | $\mu_i$ | $\eta_i$ |
| Log | $\log(\mu_i)$ | $\exp(\eta_i)$ |
| Inverse | $1/\mu_i$ | $1/\eta_i$ |
| Inverse-squared | $1/\mu_i^2$ | $1/\sqrt{\eta_i}$ |
| Square-root | $\sqrt{\mu_i}$ | $\eta_i^2$ |
| Logit | $\log(\mu_i/(1-\mu_i))$ | $\exp(\eta_i)/(1+\exp(\eta_i))$ |
| Probit | $\Phi^{-1}(\mu_i)$ | $\Phi(\eta_i)$ | Log-log | $\log(-\log(1-\mu_i))$ | $1-\exp(-\exp(\eta_i))$ |
| Complementary log-log | $\log(-\log(1-\mu_i))$ | $1-\exp(-\exp(\eta_i))$ |

where $\Phi(\cdot)$ is the cumulative distribution function of the standard normal distribution.

## Canonical link

| Family | Canonical Link | Range of $Y_i$ | $V(Y_i|\eta_i)$ |
|--------|-----------------|---------------|-----------------|
| Normal | Identity | $(-\infty, \infty)$ | $\psi$ |
| Binomial | Logit | $[0, 1]$ | $\mu_i(1-\mu_i)$ |
| Poisson | Log | $[0, \infty)$ | $\mu_i$ |
| Gamma | Inverse | $(0, \infty)$ | $\psi\mu_i^2$ |
| Inverse-Gaussian | Inverse-squared | $(0, \infty)$ | $\psi\mu_i^3$ |

where $\psi$ is the dispersion parameter, $\eta_i$ is the linear predictor, and $\mu_i$ is the expectation of $Y_i$. In the binomial family, $n_i$ is the number of trials.
